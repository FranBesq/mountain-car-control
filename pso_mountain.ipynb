{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving mountain car problem with PSO\n",
    "\n",
    "In this notebook particle swarm optimization (PSO) is used to adjust a PID that solves [mountain car problem](https://en.wikipedia.org/wiki/Mountain_car_problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import some dependencies and define max number of steps to take in simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pso\n",
    "from simple_pid import PID\n",
    "from env.mountain_car_env import Continuous_MountainCarEnv\n",
    "\n",
    "MAX_STEPS = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function\n",
    "\n",
    "The key part when implementing pso is defining a cost function. Each particle is going to try and minimize whatever signal we choose to set as cost. In this case the obvious choice is to try and minimize error, so we could set the cost as the distance to the goal. This has problems converging, so we ended up setting the cost as the force needed to get to the goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing we need to extract the PID parameters from the particle. Then the simulation can start using the PID to select an action based on this cost signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mountain_sim(x):\n",
    "    # Get pid params from particle\n",
    "    k_p = x[0]\n",
    "    k_i = x[1]\n",
    "    k_d = x[2]\n",
    "\n",
    "    # Create the pid\n",
    "    pid = PID(k_p, k_i, k_d, setpoint=1)\n",
    "    \n",
    "    # Initilize sim\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    reward = 0\n",
    "    errTotal = 0 # Cumulative error is our cost \n",
    "\n",
    "    for i in range(MAX_STEPS):\n",
    "        #err = abs(min(obs[0] - GOAL_POS, 0)) # absolute value of: Position - goal\n",
    "        action = pid(reward)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        # Get cost/err\n",
    "        errTotal += reward # Reward corresponds to the square of force used divided by 100\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    return errTotal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set PSO parameters\n",
    "\n",
    "In order to use PSO the number of variables of each particle and the min/max values they can take must be defined. For a detail explanation of each parameter visit [yarpiz](https://yarpiz.com/50/ypea102-particle-swarm-optimization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = {\n",
    "    'CostFunction': mountain_sim,\n",
    "    'nVar': 3,      # K_p, K_i, K_d\n",
    "    'VarMin': -5,   # Min value of each parameter of the PID\n",
    "    'VarMax': 5,    # Max value of each parameter of the PID\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PSO\n",
    "\n",
    "Now that the problems is well defined we can run PSO and wait for a solution to our PID.\n",
    "You can run this section many times until you get a solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First start the simulation of mountain car problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Continuous_MountainCarEnv()\n",
    "GOAL_POS = env.goal_position # Get goal position from env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some pso hyper-parameters and start optimization. This may take some time depending on MAX_STEPS, PopSize and MaxIter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running PSO\n",
    "pso.tic()\n",
    "print('Running PSO ...')\n",
    "gbest, pop = pso.PSO(problem, MaxIter=200, PopSize=25)\n",
    "env.close()\n",
    "pso.toc()\n",
    "print('Global Best:')\n",
    "print(gbest)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enjoy the best agent\n",
    "\n",
    "Now simulation is over we take the best agent from pso and try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enjoy best\n",
    "k_p = gbest[\"position\"][0]\n",
    "k_i = gbest[\"position\"][1]\n",
    "k_d = gbest[\"position\"][2]\n",
    "\n",
    "# If optimization did not get you a solution try this PID\n",
    "\n",
    "#k_p = -5 \n",
    "#k_i = 0.20339942 \n",
    "#k_d = -5 \n",
    "\n",
    "\n",
    "pid = PID(k_p, k_i, k_d, setpoint=1)\n",
    "\n",
    "# Initilize sim\n",
    "env = Continuous_MountainCarEnv()\n",
    "obs = env.reset()\n",
    "done = False\n",
    "\n",
    "for i in range(MAX_STEPS):\n",
    "    env.render()\n",
    "    err = min(obs[0] - GOAL_POS, 0)\n",
    "    action = pid(err)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
